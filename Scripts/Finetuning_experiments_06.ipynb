{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac55e0a",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb8abb3",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1461182b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read data per attack\n",
    "# Order of attacks: SYN - ICMP - UDP - DNS - GTPU \n",
    "folder_path = '../Datasets/Per_Attack_Datasets'\n",
    "\n",
    "# Create an empty dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Load each CSV file into a separate DataFrame\n",
    "for csv_file in csv_files:\n",
    "    attack = os.path.splitext(csv_file)[0] \n",
    "    \n",
    "    # Load the CSV file\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    dataframes[attack] = pd.read_csv(file_path)\n",
    "\n",
    "# Check loaded DataFrames\n",
    "for attack, df in dataframes.items():\n",
    "    print(f\"DataFrame for {attack}:\")\n",
    "    print(df.head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c3185",
   "metadata": {},
   "source": [
    "### Auxiliary Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d003b",
   "metadata": {},
   "source": [
    "#### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1494f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['bearer_0_dl_total_bytes', 'bearer_0_ul_total_bytes','bearer_1_dl_total_bytes',\n",
    "            'bearer_1_ul_total_bytes','ul_path_loss','ul_phr','turbo_decoder_avg','epre','pusch_snr','p_ue','ul_mcs','cqi','ul_bitrate',\n",
    "            'dl_mcs','dl_retx','ul_tx','dl_tx','ul_retx','dl_bitrate','dl_err','ul_err']\n",
    "num_features = [14, 11, 8, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c178c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the above features\n",
    "def scale_df(data,features):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data[features] = scaler.fit_transform(data[features])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1041d4a5",
   "metadata": {},
   "source": [
    "#### Create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f16eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences for a single user-event group\n",
    "def create_sequences_for_group(group, features, target, sequence_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(group) - sequence_length):\n",
    "        seq_features = group[features].iloc[i:i + sequence_length].values\n",
    "        seq_label = group[target].iloc[i + sequence_length]\n",
    "        sequences.append(seq_features)\n",
    "        labels.append(seq_label)\n",
    "    return sequences, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb43dc1",
   "metadata": {},
   "source": [
    "#### Create LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78796a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classification with a One-Layer LSTM\n",
    "def create_lstm_model_binary(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(32, input_shape=input_shape),  # One LSTM layer with 32 units\n",
    "        Dropout(0.3),  # Dropout rate of 0.3 to reduce overfitting\n",
    "        Dense(1, activation='sigmoid')  # Binary classification output with sigmoid\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)  # Adam optimizer with learning rate = 0.01\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d20909-d0bf-4c7e-8b9f-d9903def6042",
   "metadata": {},
   "source": [
    "#### LSTM parameters finetuning (window size = 5, features = 14, ratio = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8693a8-ece3-4d8c-85c6-7a9aea1271b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "hyperparameter_grid = {\n",
    "    \"lstm_units\": [16, 32, 64],      # Number of LSTM units\n",
    "    \"num_layers\": [1],               # Number of layers\n",
    "    \"dropout_rate\": [0.1, 0.2, 0.3], # Dropout rates\n",
    "    \"learning_rate\": [0.001, 0.01],  # Learning rates\n",
    "    \"batch_size\": [32, 64, 128, 256, 1024],  # Batch sizes\n",
    "}\n",
    "\n",
    "# Experiment parameters\n",
    "ws = 5  # Window sizes\n",
    "attacks = ['SYN', 'ICMP', 'UDP', 'DNS', 'GTPU']\n",
    "output_dir = \"lstm_fine_tune_results_new/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Remove features from the start\n",
    "start_remove = len(features) - num_features[0]\n",
    "curr_features = features[start_remove:]\n",
    "print(f\"Using features: {curr_features}\")\n",
    "\n",
    "# Pre-load and preprocess data for all attacks\n",
    "preprocessed_data = {}\n",
    "for attack in attacks:\n",
    "    print(f\"Preprocessing data for {attack}\")\n",
    "    data = dataframes[attack]\n",
    "    data = data.drop(columns=['attack', 'malicious', 'attack_number'])\n",
    "    data_norm = scale_df(data, curr_features)\n",
    "    data_norm['_time'] = pd.to_datetime(data_norm['_time'])  # Parse time column\n",
    "    data_norm.sort_values(by=['imeisv', '_time'], inplace=True)  # Sort by UE ID and time\n",
    "    \n",
    "    sequences, labels = [], []\n",
    "    target = 'binary_label'\n",
    "    for (imeisv, event), group in data_norm.groupby(['imeisv', 'event']):\n",
    "        if len(group) > ws:  # Process groups with enough data\n",
    "            seqs, lbls = create_sequences_for_group(group, curr_features, target, ws)\n",
    "            sequences.extend(seqs)\n",
    "            labels.extend(lbls)\n",
    "    preprocessed_data[attack] = (np.array(sequences), np.array(labels))\n",
    "\n",
    "# Function to create LSTM model\n",
    "def create_lstm_model(input_shape, lstm_units, num_layers, dropout_rate, learning_rate):\n",
    "    model = models.Sequential()\n",
    "    for i in range(num_layers):\n",
    "        return_sequences = i < num_layers - 1  # Return sequences for intermediate layers\n",
    "        model.add(layers.LSTM(lstm_units, return_sequences=return_sequences, input_shape=input_shape))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))  # Binary classification\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\", \"Precision\", \"Recall\"])\n",
    "    return model\n",
    "\n",
    "# Initialize results storage\n",
    "all_results = []\n",
    "cumulative_results_day_5 = []\n",
    "\n",
    "# Fine-tuning loop\n",
    "for lstm_units in hyperparameter_grid[\"lstm_units\"]:\n",
    "    for num_layers in hyperparameter_grid[\"num_layers\"]:\n",
    "        for dropout_rate in hyperparameter_grid[\"dropout_rate\"]:\n",
    "            for learning_rate in hyperparameter_grid[\"learning_rate\"]:\n",
    "                for batch_size in hyperparameter_grid[\"batch_size\"]:\n",
    "                    print(f\"Training with LSTM Units: {lstm_units}, Layers: {num_layers}, Dropout: {dropout_rate}, \"\n",
    "                          f\"Learning Rate: {learning_rate}, Batch Size: {batch_size}\")\n",
    "\n",
    "                    # Initialize variables\n",
    "                    cumulative_X_test, cumulative_y_test = [], []\n",
    "                    per_day_results = []\n",
    "\n",
    "                    # Training and evaluation loop\n",
    "                    for i, attack in enumerate(attacks):\n",
    "                        print(f\"Processing {attack}\")\n",
    "                        X, y = preprocessed_data[attack]\n",
    "                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "                        cumulative_X_test.append(X_test)\n",
    "                        cumulative_y_test.append(y_test)\n",
    "\n",
    "                        # Concatenate cumulative test sets for evaluation\n",
    "                        X_cumulative_test = np.concatenate(cumulative_X_test, axis=0)\n",
    "                        y_cumulative_test = np.concatenate(cumulative_y_test, axis=0)\n",
    "\n",
    "                        # Train or fine-tune the model\n",
    "                        if i == 0: \n",
    "                            # Initial training\n",
    "                            model = create_lstm_model(\n",
    "                                input_shape=X_train.shape[1:], \n",
    "                                lstm_units=lstm_units, \n",
    "                                num_layers=num_layers, \n",
    "                                dropout_rate=dropout_rate, \n",
    "                                learning_rate=learning_rate\n",
    "                            )\n",
    "                            model.fit(X_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.2)\n",
    "                        else:\n",
    "                            # Fine-tune\n",
    "                            model.fit(X_train, y_train, epochs=5, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "                        # Evaluate on current test set\n",
    "                        print(f\"Evaluating Model on Day {i + 1}\")\n",
    "                        loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "                        per_day_results.append({\n",
    "                            \"day\": i + 1,\n",
    "                            \"loss\": loss,\n",
    "                            \"accuracy\": accuracy,\n",
    "                            \"precision\": precision,\n",
    "                            \"recall\": recall,\n",
    "                            \"lstm_units\": lstm_units,\n",
    "                            \"num_layers\": num_layers,\n",
    "                            \"dropout_rate\": dropout_rate,\n",
    "                            \"learning_rate\": learning_rate,\n",
    "                            \"batch_size\": batch_size,\n",
    "                            \"window_size\": ws,\n",
    "                        })\n",
    "\n",
    "                        # Save cumulative results for Day 5\n",
    "                        if i == 4:  # Day 5 corresponds to index 4\n",
    "                            cumulative_loss, cumulative_accuracy, cumulative_precision, cumulative_recall = model.evaluate(\n",
    "                                X_cumulative_test, y_cumulative_test, verbose=0)\n",
    "                            cumulative_results_day_5.append({\n",
    "                                \"lstm_units\": lstm_units,\n",
    "                                \"num_layers\": num_layers,\n",
    "                                \"dropout_rate\": dropout_rate,\n",
    "                                \"learning_rate\": learning_rate,\n",
    "                                \"batch_size\": batch_size,\n",
    "                                \"window_size\": ws,\n",
    "                                \"loss\": cumulative_loss,\n",
    "                                \"accuracy\": cumulative_accuracy,\n",
    "                                \"precision\": cumulative_precision,\n",
    "                                \"recall\": cumulative_recall,\n",
    "                            })\n",
    "\n",
    "                    # Save results to all_results\n",
    "                    all_results.extend(per_day_results)\n",
    "\n",
    "# Export all results to a CSV\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_filename = os.path.join(output_dir, \"lstm_hyperparameter_tuning_results.csv\")\n",
    "results_df.to_csv(results_filename, index=False)\n",
    "print(f\"Results saved to {results_filename}\")\n",
    "\n",
    "# Export cumulative results for Day 5 to a separate CSV\n",
    "cumulative_results_df = pd.DataFrame(cumulative_results_day_5)\n",
    "cumulative_results_filename = os.path.join(output_dir, \"cumulative_results_day_5.csv\")\n",
    "cumulative_results_df.to_csv(cumulative_results_filename, index=False)\n",
    "print(f\"Cumulative results for Day 5 saved to {cumulative_results_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c4ca8b-d165-4b45-b499-2f4d0c0a4266",
   "metadata": {},
   "source": [
    "#### Features used fine tuning (ratio = 0.0, window size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48442bea-88d6-4e82-89ff-f6f64bda7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_data_ratio = 0.0 # ratio of previous training data to be used\n",
    "ws = 5 # window size\n",
    "for n_features in num_features:\n",
    "    print(f\"\\nExperiment with {len(features) - n_features} features removed...\")\n",
    "    \n",
    "    # Remove features from the start\n",
    "    start_remove = len(features) - n_features\n",
    "    curr_features = features[start_remove:]\n",
    "    print(f\"Using features: {curr_features}\")\n",
    "\n",
    "    models = []\n",
    "    results = []\n",
    "    per_day_results = []  # Store per-day evaluations\n",
    "    future_days_evaluation = {}  # Store future days' evaluations\n",
    "    past_evaluation_results = {}  # Store evaluations on previous days' test sets\n",
    "    attacks = ['SYN', 'ICMP', 'UDP', 'DNS', 'GTPU']\n",
    "    \n",
    "    # Initialize cumulative test sets\n",
    "    cumulative_X_test = []\n",
    "    cumulative_y_test = []\n",
    "    \n",
    "    # Initialize a dictionary to store test sets for future and past evaluations\n",
    "    test_sets = {}\n",
    "    \n",
    "    # Initialize buffers for sampled data \n",
    "    previous_normal_data = []\n",
    "    previous_attack_data = []\n",
    "\n",
    "    # Training and fine-tuning loop\n",
    "    for i, attack in enumerate(attacks):\n",
    "        print(f\"Processing {attack}\")\n",
    "        \n",
    "        # 0) Get Data\n",
    "        data = dataframes[attack]\n",
    "        data = data.drop(columns=['attack', 'malicious', 'attack_number'])\n",
    "    \n",
    "        # 1) Normalize Data\n",
    "        print(\"Normalizing Data\")\n",
    "        data_norm = scale_df(data, curr_features)\n",
    "    \n",
    "        # 2) Create Sequences\n",
    "        print(\"Creating Sequences\")\n",
    "        data_norm['_time'] = pd.to_datetime(data_norm['_time'])  # Parse time column\n",
    "        data_norm.sort_values(by=['imeisv', '_time'], inplace=True)  # Sort by UE ID and time\n",
    "    \n",
    "        all_sequences = []\n",
    "        all_labels = []\n",
    "        target = 'binary_label'\n",
    "        for (imeisv, event), group in data_norm.groupby(['imeisv', 'event']):\n",
    "            if len(group) > ws:  # Only process groups with enough data\n",
    "                sequences, labels = create_sequences_for_group(group, curr_features, target, ws)\n",
    "                all_sequences.extend(sequences)\n",
    "                all_labels.extend(labels)\n",
    "    \n",
    "        # 3) Split train/test\n",
    "        print(\"Splitting Sequences\")\n",
    "        X = np.array(all_sequences)\n",
    "        y = np.array(all_labels)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "        \n",
    "        # Save current test set for evaluations\n",
    "        test_sets[i] = (X_test, y_test)\n",
    "        \n",
    "        # Append current test set to cumulative test sets\n",
    "        cumulative_X_test.append(X_test)\n",
    "        cumulative_y_test.append(y_test)\n",
    "        \n",
    "        # Concatenate cumulative test sets for evaluation\n",
    "        X_cumulative_test = np.concatenate(cumulative_X_test, axis=0)\n",
    "        y_cumulative_test = np.concatenate(cumulative_y_test, axis=0)\n",
    "    \n",
    "        # Stratified mixing of previous data\n",
    "        if i > 0 and (previous_normal_data or previous_attack_data):\n",
    "            print(f\"Mixing {previous_data_ratio * 100:.0f}% of previous days' data with current day's data\")\n",
    "            \n",
    "            # Combine all previous samples\n",
    "            sampled_X_normal = np.concatenate(previous_normal_data, axis=0)\n",
    "            sampled_X_attack = np.concatenate(previous_attack_data, axis=0)\n",
    "\n",
    "            # Combine normal and attack samples\n",
    "            sampled_previous_X = np.concatenate((sampled_X_normal, sampled_X_attack), axis=0)\n",
    "            sampled_previous_y = np.concatenate((np.zeros(len(sampled_X_normal)), np.ones(len(sampled_X_attack))), axis=0)\n",
    "\n",
    "            # Combine sampled previous data with current day's training data\n",
    "            mixed_X_train = np.concatenate((X_train, sampled_previous_X), axis=0)\n",
    "            mixed_y_train = np.concatenate((y_train, sampled_previous_y), axis=0)\n",
    "\n",
    "            # Shuffle the combined data\n",
    "            mixed_X_train, mixed_y_train = shuffle(mixed_X_train, mixed_y_train, random_state=42)\n",
    "        else:\n",
    "            mixed_X_train = X_train\n",
    "            mixed_y_train = y_train\n",
    "\n",
    "        # Train or fine-tune the model\n",
    "        if i == 0:\n",
    "            # Initial training\n",
    "            model = create_lstm_model_binary(input_shape=X_train.shape[1:])\n",
    "            model.fit(mixed_X_train, mixed_y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "        else:\n",
    "            # Fine-tune\n",
    "            model.fit(mixed_X_train, mixed_y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "    \n",
    "        # Save the model\n",
    "        models.append(model)\n",
    "    \n",
    "        # Per-Day Evaluation\n",
    "        print(f\"Evaluating Model of Day {i + 1} on Day {i + 1} Test Set...\")\n",
    "        per_day_loss, per_day_accuracy, per_day_precision, per_day_recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "        per_day_results.append({\n",
    "            \"day\": i + 1,\n",
    "            \"loss\": per_day_loss,\n",
    "            \"accuracy\": per_day_accuracy,\n",
    "            \"precision\": per_day_precision,\n",
    "            \"recall\": per_day_recall,\n",
    "        })\n",
    "        print(f\"Day {i + 1} Per-Day Test Loss: {per_day_loss:.4f}, Accuracy: {per_day_accuracy:.4f}, \"\n",
    "              f\"Precision: {per_day_precision:.4f}, Recall: {per_day_recall:.4f}\")\n",
    "    \n",
    "        # Evaluate on cumulative test set\n",
    "        cumulative_loss, cumulative_accuracy, cumulative_precision, cumulative_recall = model.evaluate(X_cumulative_test, y_cumulative_test, verbose=0)\n",
    "        results.append({\n",
    "            \"day\": i + 1,\n",
    "            \"loss\": cumulative_loss,\n",
    "            \"accuracy\": cumulative_accuracy,\n",
    "            \"precision\": cumulative_precision,\n",
    "            \"recall\": cumulative_recall\n",
    "        })\n",
    "        print(f\"Day {i+1} Cumulative Test Loss: {cumulative_loss:.4f}, Accuracy: {cumulative_accuracy:.4f}\")\n",
    "    \n",
    "        # Evaluate on previous days' test sets\n",
    "        if i > 0:\n",
    "            print(f\"Evaluating Model of Day {i + 1} on Previous Days' Test Sets:\")\n",
    "            for prev_day in range(i):\n",
    "                prev_X_test, prev_y_test = test_sets[prev_day]\n",
    "                prev_loss, prev_accuracy, prev_precision, prev_recall = model.evaluate(prev_X_test, prev_y_test, verbose=0)\n",
    "                # Save results\n",
    "                past_evaluation_results[(i + 1, prev_day + 1)] = {\n",
    "                    \"model_day\": i + 1,\n",
    "                    \"test_day\": prev_day + 1,\n",
    "                    \"loss\": prev_loss,\n",
    "                    \"accuracy\": prev_accuracy,\n",
    "                    \"precision\": prev_precision,\n",
    "                    \"recall\": prev_recall,\n",
    "                }\n",
    "                print(f\"  Model of Day {i + 1} -> Test Set Day {prev_day + 1}: Loss = {prev_loss:.4f}, \"\n",
    "                      f\"Accuracy = {prev_accuracy:.4f}, Precision = {prev_precision:.4f}, Recall = {prev_recall:.4f}\")\n",
    "\n",
    "    # Perform evaluations on future test sets\n",
    "    print(\"\\nPerforming Future Test Set Evaluations:\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Evaluating Model of Day {i + 1} on Future Test Sets:\")\n",
    "        for j in range(i + 1, len(attacks)):  # Evaluate on test sets of future days\n",
    "            future_X_test, future_y_test = test_sets[j]\n",
    "            future_loss, future_accuracy, future_precision, future_recall = model.evaluate(future_X_test, future_y_test, verbose=0)\n",
    "            # Save results for future evaluations\n",
    "            future_days_evaluation[(i + 1, j + 1)] = {\n",
    "                \"model_day\": i + 1,\n",
    "                \"future_day\": j + 1,\n",
    "                \"loss\": future_loss,\n",
    "                \"accuracy\": future_accuracy,\n",
    "                \"precision\": future_precision,\n",
    "                \"recall\": future_recall,\n",
    "            }\n",
    "            print(f\"  Model of Day {i + 1} -> Future Test Set Day {j + 1}: Loss = {future_loss:.4f}, \"\n",
    "                  f\"Accuracy = {future_accuracy:.4f}, Precision = {future_precision:.4f}, Recall = {future_recall:.4f}\")\n",
    "\n",
    "        # Sampling data from the current day's training set for future use\n",
    "        print(f\"Sampling data from current training set for future use...\")\n",
    "        normal_indices = y_train == 0\n",
    "        attack_indices = y_train == 1\n",
    "\n",
    "        # Shuffle and sample normal data\n",
    "        shuffled_normal_X = shuffle(X_train[normal_indices], random_state=42)\n",
    "        num_normal_samples = int(previous_data_ratio * len(y_train)) // 2\n",
    "        previous_normal_data.append(shuffled_normal_X[:num_normal_samples])\n",
    "\n",
    "        # Shuffle and sample attack data\n",
    "        shuffled_attack_X = shuffle(X_train[attack_indices], random_state=42)\n",
    "        num_attack_samples = int(previous_data_ratio * len(y_train)) - num_normal_samples\n",
    "        previous_attack_data.append(shuffled_attack_X[:num_attack_samples])\n",
    "\n",
    "    # Reset previous data buffers after processing all attacks for this feature configuration\n",
    "    previous_normal_data = []\n",
    "    previous_attack_data = []\n",
    "    print(\"Reset previous data buffers for the next feature configuration.\")\n",
    "\n",
    "    # Export Results to CSV\n",
    "    print(\"\\nExporting Results to CSV...\")\n",
    "    output_dir = \"ft/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    per_day_filename = f\"{output_dir}per_day_results_seq_{ws}_removed_{len(features) - n_features}.csv\"\n",
    "    cumulative_filename = f\"{output_dir}cumulative_results_seq_{ws}_removed_{len(features) - n_features}.csv\"\n",
    "    past_filename = f\"{output_dir}past_evaluation_results_seq_{ws}_removed_{len(features) - n_features}.csv\"\n",
    "    future_filename = f\"{output_dir}future_days_evaluation_seq_{ws}_removed_{len(features) - n_features}.csv\"\n",
    "\n",
    "    try:\n",
    "        pd.DataFrame(per_day_results).to_csv(per_day_filename, index=False)\n",
    "        pd.DataFrame(results).to_csv(cumulative_filename, index=False)\n",
    "        pd.DataFrame(past_evaluation_results).T.reset_index(drop=True).to_csv(past_filename, index=False)\n",
    "        pd.DataFrame(future_days_evaluation).T.reset_index(drop=True).to_csv(future_filename, index=False)\n",
    "        print(f\"Results saved: {output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1953c53a-586b-44ac-9f61-b4d76a127976",
   "metadata": {},
   "source": [
    "#### Experiments to determine the best ratio of previous data to use (windows_size = 5, features = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e63c45-760c-4f28-856d-5328fa82a806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the range of previous data ratios to experiment with\n",
    "previous_data_ratios = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "# Experiment parameters\n",
    "fixed_window_size = 5  # Fixed window size\n",
    "fixed_n_features = 14  # Constant number of features to keep\n",
    "start_remove = len(features) - fixed_n_features\n",
    "curr_features = features[start_remove:]\n",
    "print(f\"Using features: {curr_features}\")\n",
    "\n",
    "output_dir_base = \"ft_experiment_results/\"\n",
    "os.makedirs(output_dir_base, exist_ok=True)\n",
    "\n",
    "for previous_data_ratio in previous_data_ratios:\n",
    "    print(f\"\\n--- Experiment with previous data ratio: {previous_data_ratio} ---\")\n",
    "    output_dir = os.path.join(output_dir_base, f\"ratio_{int(previous_data_ratio * 100):02d}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    models = []\n",
    "    results = []\n",
    "    per_day_results = []  # Store per-day evaluations\n",
    "    future_days_evaluation = {}  # Store future days' evaluations\n",
    "    past_evaluation_results = {}  # Store evaluations on previous days' test sets\n",
    "    attacks = ['SYN', 'ICMP', 'UDP', 'DNS', 'GTPU']\n",
    "\n",
    "    # Initialize cumulative test sets\n",
    "    cumulative_X_test = []\n",
    "    cumulative_y_test = []\n",
    "\n",
    "    # Initialize buffers for sampled data \n",
    "    previous_normal_data = []\n",
    "    previous_attack_data = []\n",
    "\n",
    "    # Training and fine-tuning loop\n",
    "    for i, attack in enumerate(attacks):\n",
    "        print(f\"Processing {attack}\")\n",
    "\n",
    "        # 0) Get Data\n",
    "        data = dataframes[attack]\n",
    "        data = data.drop(columns=['attack', 'malicious', 'attack_number'])\n",
    "\n",
    "        # 1) Normalize Data\n",
    "        print(\"Normalizing Data\")\n",
    "        data_norm = scale_df(data, curr_features)\n",
    "\n",
    "        # 2) Create Sequences\n",
    "        print(\"Creating Sequences\")\n",
    "        data_norm['_time'] = pd.to_datetime(data_norm['_time'])  # Parse time column\n",
    "        data_norm.sort_values(by=['imeisv', '_time'], inplace=True)  # Sort by UE ID and time\n",
    "\n",
    "        all_sequences = []\n",
    "        all_labels = []\n",
    "        target = 'binary_label'\n",
    "        for (imeisv, event), group in data_norm.groupby(['imeisv', 'event']):\n",
    "            if len(group) > fixed_window_size:  # Only process groups with enough data\n",
    "                sequences, labels = create_sequences_for_group(group, curr_features, target, fixed_window_size)\n",
    "                all_sequences.extend(sequences)\n",
    "                all_labels.extend(labels)\n",
    "\n",
    "        # 3) Split train/test\n",
    "        print(\"Splitting Sequences\")\n",
    "        X = np.array(all_sequences)\n",
    "        y = np.array(all_labels)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "        # Save current test set for evaluations\n",
    "        test_sets[i] = (X_test, y_test)\n",
    "\n",
    "        # Append current test set to cumulative test sets\n",
    "        cumulative_X_test.append(X_test)\n",
    "        cumulative_y_test.append(y_test)\n",
    "\n",
    "        # Concatenate cumulative test sets for evaluation\n",
    "        X_cumulative_test = np.concatenate(cumulative_X_test, axis=0)\n",
    "        y_cumulative_test = np.concatenate(cumulative_y_test, axis=0)\n",
    "\n",
    "        # Stratified mixing of previous data\n",
    "        if i > 0 and (previous_normal_data or previous_attack_data):\n",
    "            print(f\"Mixing {previous_data_ratio * 100:.0f}% of previous days' data with current day's data\")\n",
    "\n",
    "            # Combine all previous samples\n",
    "            sampled_X_normal = np.concatenate(previous_normal_data, axis=0)\n",
    "            sampled_X_attack = np.concatenate(previous_attack_data, axis=0)\n",
    "\n",
    "            # Combine normal and attack samples\n",
    "            sampled_previous_X = np.concatenate((sampled_X_normal, sampled_X_attack), axis=0)\n",
    "            sampled_previous_y = np.concatenate((np.zeros(len(sampled_X_normal)), np.ones(len(sampled_X_attack))), axis=0)\n",
    "\n",
    "            # Combine sampled previous data with current day's training data\n",
    "            mixed_X_train = np.concatenate((X_train, sampled_previous_X), axis=0)\n",
    "            mixed_y_train = np.concatenate((y_train, sampled_previous_y), axis=0)\n",
    "\n",
    "            # Shuffle the combined data\n",
    "            mixed_X_train, mixed_y_train = shuffle(mixed_X_train, mixed_y_train, random_state=42)\n",
    "        else:\n",
    "            mixed_X_train = X_train\n",
    "            mixed_y_train = y_train\n",
    "\n",
    "        # Train or fine-tune the model\n",
    "        if i == 0:\n",
    "            # Initial training\n",
    "            model = create_lstm_model_binary(input_shape=mixed_X_train.shape[1:])\n",
    "            model.fit(mixed_X_train, mixed_y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "        else:\n",
    "            # Fine-tune\n",
    "            model.fit(mixed_X_train, mixed_y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "        # Save the model\n",
    "        models.append(model)\n",
    "\n",
    "        # Per-Day Evaluation\n",
    "        print(f\"Evaluating Model of Day {i + 1} on Day {i + 1} Test Set...\")\n",
    "        per_day_loss, per_day_accuracy, per_day_precision, per_day_recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "        per_day_results.append({\n",
    "            \"day\": i + 1,\n",
    "            \"loss\": per_day_loss,\n",
    "            \"accuracy\": per_day_accuracy,\n",
    "            \"precision\": per_day_precision,\n",
    "            \"recall\": per_day_recall,\n",
    "        })\n",
    "        print(f\"Day {i + 1} Per-Day Test Loss: {per_day_loss:.4f}, Accuracy: {per_day_accuracy:.4f}, \"\n",
    "              f\"Precision: {per_day_precision:.4f}, Recall: {per_day_recall:.4f}\")\n",
    "\n",
    "        # Evaluate on cumulative test set\n",
    "        cumulative_loss, cumulative_accuracy, cumulative_precision, cumulative_recall = model.evaluate(X_cumulative_test, y_cumulative_test, verbose=0)\n",
    "        results.append({\n",
    "            \"day\": i + 1,\n",
    "            \"loss\": cumulative_loss,\n",
    "            \"accuracy\": cumulative_accuracy,\n",
    "            \"precision\": cumulative_precision,\n",
    "            \"recall\": cumulative_recall\n",
    "        })\n",
    "        print(f\"Day {i+1} Cumulative Test Loss: {cumulative_loss:.4f}, Accuracy: {cumulative_accuracy:.4f}\")\n",
    "\n",
    "        # Sampling data from the current day's training set for future use\n",
    "        print(f\"Sampling data from current training set for future use...\")\n",
    "        normal_indices = y_train == 0\n",
    "        attack_indices = y_train == 1\n",
    "\n",
    "        # Shuffle and sample normal data\n",
    "        shuffled_normal_X = shuffle(X_train[normal_indices], random_state=42)\n",
    "        num_normal_samples = int(previous_data_ratio * len(y_train)) // 2\n",
    "        previous_normal_data.append(shuffled_normal_X[:num_normal_samples])\n",
    "\n",
    "        # Shuffle and sample attack data\n",
    "        shuffled_attack_X = shuffle(X_train[attack_indices], random_state=42)\n",
    "        num_attack_samples = int(previous_data_ratio * len(y_train)) - num_normal_samples\n",
    "        previous_attack_data.append(shuffled_attack_X[:num_attack_samples])\n",
    "\n",
    "    # Reset previous data buffers after processing all attacks\n",
    "    previous_normal_data = []\n",
    "    previous_attack_data = []\n",
    "    print(\"Reset previous data buffers for the next previous_data_ratio configuration.\")\n",
    "\n",
    "    # Export Results to CSV\n",
    "    print(\"\\nExporting Results to CSV...\")\n",
    "\n",
    "    per_day_filename = f\"{output_dir}/per_day_results_removed_{len(features) - fixed_n_features}.csv\"\n",
    "    cumulative_filename = f\"{output_dir}/cumulative_results_removed_{len(features) - fixed_n_features}.csv\"\n",
    "\n",
    "    try:\n",
    "        pd.DataFrame(per_day_results).to_csv(per_day_filename, index=False)\n",
    "        pd.DataFrame(results).to_csv(cumulative_filename, index=False)\n",
    "        print(f\"Results saved to {output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea5213-ca99-40eb-91a5-2fe40d151bf2",
   "metadata": {},
   "source": [
    "#### Experiments for ideal window size (ratio=0.3, features=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b54f36-f98f-44ba-9d74-23716c6fb9bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ratio for mixing previous training data with the current day\n",
    "previous_data_ratio = 0.3\n",
    "\n",
    "# Experiment parameters\n",
    "window_size = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "n_features = 14  # Fixed number of features\n",
    "\n",
    "for ws in window_size:\n",
    "    print(f\"\\n--- Window size: {ws} ---\")\n",
    "    \n",
    "    print(f\"\\nExperiment with {len(features) - n_features} features removed...\")\n",
    "    \n",
    "    # Remove features from the start\n",
    "    start_remove = len(features) - n_features\n",
    "    curr_features = features[start_remove:]\n",
    "    print(f\"Using features: {curr_features}\")\n",
    "    \n",
    "    models = []\n",
    "    results = []\n",
    "    per_day_results = []  # Store per-day evaluations\n",
    "    future_days_evaluation = {}  # Store future days' evaluations\n",
    "    past_evaluation_results = {}  # Store evaluations on previous days' test sets\n",
    "    attacks = ['SYN', 'ICMP', 'UDP', 'DNS', 'GTPU']\n",
    "    \n",
    "    # Initialize cumulative test sets\n",
    "    cumulative_X_test = []\n",
    "    cumulative_y_test = []\n",
    "    \n",
    "    # Initialize a dictionary to store test sets for future and past evaluations\n",
    "    test_sets = {}\n",
    "    \n",
    "    # Initialize buffers for sampled data \n",
    "    previous_normal_data = []\n",
    "    previous_attack_data = []\n",
    "\n",
    "    # Training and fine-tuning loop\n",
    "    for i, attack in enumerate(attacks):\n",
    "        print(f\"Processing {attack}\")\n",
    "        \n",
    "        # 0) Get Data\n",
    "        data = dataframes[attack]\n",
    "        data = data.drop(columns=['attack', 'malicious', 'attack_number'])\n",
    "    \n",
    "        # 1) Normalize Data\n",
    "        print(\"Normalizing Data\")\n",
    "        data_norm = scale_df(data, curr_features)\n",
    "    \n",
    "        # 2) Create Sequences\n",
    "        print(\"Creating Sequences\")\n",
    "        data_norm['_time'] = pd.to_datetime(data_norm['_time'])  # Parse time column\n",
    "        data_norm.sort_values(by=['imeisv', '_time'], inplace=True)  # Sort by UE ID and time\n",
    "    \n",
    "        all_sequences = []\n",
    "        all_labels = []\n",
    "        target = 'binary_label'\n",
    "        for (imeisv, event), group in data_norm.groupby(['imeisv', 'event']):\n",
    "            if len(group) > ws:  # Only process groups with enough data\n",
    "                sequences, labels = create_sequences_for_group(group, curr_features, target, ws)\n",
    "                all_sequences.extend(sequences)\n",
    "                all_labels.extend(labels)\n",
    "    \n",
    "        # 3) Split train/test\n",
    "        print(\"Splitting Sequences\")\n",
    "        X = np.array(all_sequences)\n",
    "        y = np.array(all_labels)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "        \n",
    "        # Save current test set for evaluations\n",
    "        test_sets[i] = (X_test, y_test)\n",
    "        \n",
    "        # Append current test set to cumulative test sets\n",
    "        cumulative_X_test.append(X_test)\n",
    "        cumulative_y_test.append(y_test)\n",
    "        \n",
    "        # Concatenate cumulative test sets for evaluation\n",
    "        X_cumulative_test = np.concatenate(cumulative_X_test, axis=0)\n",
    "        y_cumulative_test = np.concatenate(cumulative_y_test, axis=0)\n",
    "    \n",
    "        # Stratified mixing of previous data\n",
    "        if i > 0 and (previous_normal_data or previous_attack_data):\n",
    "            print(f\"Mixing {previous_data_ratio * 100:.0f}% of previous days' data with current day's data\")\n",
    "            \n",
    "            # Combine all previous samples\n",
    "            sampled_X_normal = np.concatenate(previous_normal_data, axis=0)\n",
    "            sampled_X_attack = np.concatenate(previous_attack_data, axis=0)\n",
    "\n",
    "            # Combine normal and attack samples\n",
    "            sampled_previous_X = np.concatenate((sampled_X_normal, sampled_X_attack), axis=0)\n",
    "            sampled_previous_y = np.concatenate((np.zeros(len(sampled_X_normal)), np.ones(len(sampled_X_attack))), axis=0)\n",
    "\n",
    "            # Combine sampled previous data with current day's training data\n",
    "            mixed_X_train = np.concatenate((X_train, sampled_previous_X), axis=0)\n",
    "            mixed_y_train = np.concatenate((y_train, sampled_previous_y), axis=0)\n",
    "\n",
    "            # Shuffle the combined data\n",
    "            mixed_X_train, mixed_y_train = shuffle(mixed_X_train, mixed_y_train, random_state=42)\n",
    "        else:\n",
    "            mixed_X_train = X_train\n",
    "            mixed_y_train = y_train\n",
    "\n",
    "        # Train or fine-tune the model\n",
    "        if i == 0:\n",
    "            # Initial training\n",
    "            model = create_lstm_model_binary(input_shape=mixed_X_train.shape[1:])\n",
    "            model.fit(mixed_X_train, mixed_y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "        else:\n",
    "            # Fine-tune\n",
    "            model.fit(mixed_X_train, mixed_y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "    \n",
    "        # Save the model\n",
    "        models.append(model)\n",
    "    \n",
    "        # Per-Day Evaluation\n",
    "        print(f\"Evaluating Model of Day {i + 1} on Day {i + 1} Test Set...\")\n",
    "        per_day_loss, per_day_accuracy, per_day_precision, per_day_recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "        per_day_results.append({\n",
    "            \"day\": i + 1,\n",
    "            \"loss\": per_day_loss,\n",
    "            \"accuracy\": per_day_accuracy,\n",
    "            \"precision\": per_day_precision,\n",
    "            \"recall\": per_day_recall,\n",
    "        })\n",
    "        print(f\"Day {i + 1} Per-Day Test Loss: {per_day_loss:.4f}, Accuracy: {per_day_accuracy:.4f}, \"\n",
    "              f\"Precision: {per_day_precision:.4f}, Recall: {per_day_recall:.4f}\")\n",
    "    \n",
    "        # Evaluate on cumulative test set\n",
    "        cumulative_loss, cumulative_accuracy, cumulative_precision, cumulative_recall = model.evaluate(X_cumulative_test, y_cumulative_test, verbose=0)\n",
    "        results.append({\n",
    "            \"day\": i + 1,\n",
    "            \"loss\": cumulative_loss,\n",
    "            \"accuracy\": cumulative_accuracy,\n",
    "            \"precision\": cumulative_precision,\n",
    "            \"recall\": cumulative_recall\n",
    "        })\n",
    "        print(f\"Day {i+1} Cumulative Test Loss: {cumulative_loss:.4f}, Accuracy: {cumulative_accuracy:.4f}\")\n",
    "    \n",
    "        # Evaluate on previous days' test sets\n",
    "        if i > 0:\n",
    "            print(f\"Evaluating Model of Day {i + 1} on Previous Days' Test Sets:\")\n",
    "            for prev_day in range(i):\n",
    "                prev_X_test, prev_y_test = test_sets[prev_day]\n",
    "                prev_loss, prev_accuracy, prev_precision, prev_recall = model.evaluate(prev_X_test, prev_y_test, verbose=0)\n",
    "                # Save results\n",
    "                past_evaluation_results[(i + 1, prev_day + 1)] = {\n",
    "                    \"model_day\": i + 1,\n",
    "                    \"test_day\": prev_day + 1,\n",
    "                    \"loss\": prev_loss,\n",
    "                    \"accuracy\": prev_accuracy,\n",
    "                    \"precision\": prev_precision,\n",
    "                    \"recall\": prev_recall,\n",
    "                }\n",
    "                print(f\"  Model of Day {i + 1} -> Test Set Day {prev_day + 1}: Loss = {prev_loss:.4f}, \"\n",
    "                      f\"Accuracy = {prev_accuracy:.4f}, Precision = {prev_precision:.4f}, Recall = {prev_recall:.4f}\")\n",
    "\n",
    "\n",
    "            # Sampling data from the current day's training set for future use\n",
    "            print(f\"Sampling data from current training set for future use...\")\n",
    "            normal_indices = y_train == 0\n",
    "            attack_indices = y_train == 1\n",
    "\n",
    "            # Shuffle and sample normal data\n",
    "            shuffled_normal_X = shuffle(X_train[normal_indices], random_state=42)\n",
    "            num_normal_samples = int(previous_data_ratio * len(y_train)) // 2\n",
    "            previous_normal_data.append(shuffled_normal_X[:num_normal_samples])\n",
    "\n",
    "            # Shuffle and sample attack data\n",
    "            shuffled_attack_X = shuffle(X_train[attack_indices], random_state=42)\n",
    "            num_attack_samples = int(previous_data_ratio * len(y_train)) - num_normal_samples\n",
    "            previous_attack_data.append(shuffled_attack_X[:num_attack_samples])\n",
    "            \n",
    "    # Reset previous data buffers after processing all attacks for this feature configuration\n",
    "    previous_normal_data = []\n",
    "    previous_attack_data = []\n",
    "    print(\"Reset previous data buffers for the next feature configuration.\")\n",
    "  \n",
    "    # Export Results to CSV\n",
    "    print(\"\\nExporting Results to CSV...\")\n",
    "    output_dir = \"lstm_finetuning_window_size/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    per_day_filename = f\"{output_dir}per_day_results_seq_{ws}_removed_{len(features) - n_features}.csv\"\n",
    "    cumulative_filename = f\"{output_dir}cumulative_results_seq_{ws}_removed_{len(features) - n_features}.csv\"\n",
    "    past_filename = f\"{output_dir}past_evaluation_results_seq_{ws}_removed_{len(features) - n_features}.csv\"\n",
    "    future_filename = f\"{output_dir}future_days_evaluation_seq_{ws}_removed_{len(features) - n_features}.csv\"\n",
    "\n",
    "    try:\n",
    "        pd.DataFrame(per_day_results).to_csv(per_day_filename, index=False)\n",
    "        pd.DataFrame(results).to_csv(cumulative_filename, index=False)\n",
    "        pd.DataFrame(past_evaluation_results).T.reset_index(drop=True).to_csv(past_filename, index=False)\n",
    "        pd.DataFrame(future_days_evaluation).T.reset_index(drop=True).to_csv(future_filename, index=False)\n",
    "        print(f\"Results saved: {output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b633d7-b46c-4a09-b190-5b854607b6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
