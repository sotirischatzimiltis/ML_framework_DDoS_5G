{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51149ec-fe3d-4154-aff0-3050e11d2af1",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9971c16b-bb45-4819-a437-181698ee16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Softmax, Multiply, Lambda, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fb9a74-61ec-4399-b5d6-7a5f2fd1bbde",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4625ef2d-7488-426f-9a0f-b076f7d41d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(folder_path):\n",
    "    dataframes = {} # Create an empty dictionary to store DataFrames\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')] # List all CSV files in the folder\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        attack = os.path.splitext(csv_file)[0] \n",
    "        file_path = os.path.join(folder_path, csv_file)\n",
    "        dataframes[attack] = pd.read_csv(file_path)\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bed952-736d-4e4c-a33d-c3a2b840765c",
   "metadata": {},
   "source": [
    "#### Auxiliary Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ad4c01-7c54-4e02-8ab9-05cd20efcd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_df(data,features):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data[features] = scaler.fit_transform(data[features]) # normalize the above features\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c0e425-85fa-47d4-8256-253254594deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences for a single user-event group\n",
    "def create_sequences_for_group(group, features, target, sequence_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(group) - sequence_length):\n",
    "        seq_features = group[features].iloc[i:i + sequence_length].values\n",
    "        seq_label = group[target].iloc[i + sequence_length]\n",
    "        sequences.append(seq_features)\n",
    "        labels.append(seq_label)\n",
    "    return sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c07a07c-4eeb-42f9-b2c3-b4f8016f3bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(input_shape, lstm_units=32, learning_rate=0.01):\n",
    "    inputs = Input(shape=input_shape, name=\"input_layer\")  # Input Layer (batch_size, time_steps, features)\n",
    "    lstm_out = LSTM(lstm_units, return_sequences=False, name=\"lstm_layer\")(inputs)   # LSTM Layer  (batch_size, lstm_units)\n",
    "    outputs = Dense(1, activation=\"sigmoid\", name=\"output_layer\")(lstm_out)  # # Classification Layer (binary)\n",
    "\n",
    "    # Compile Model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df819f83-0fd5-46da-bee7-de6db3245ad1",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ab1fe0-d8f6-4e15-86fc-e9ea3cca5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_sequences(dataframes, features, ws):\n",
    "    precomputed_sequences = {}  # Store sequences for each attack\n",
    "    for attack, data in dataframes.items():\n",
    "        print(f\"🔄 Precomputing sequences for {attack}\")\n",
    "        # Drop unnecessary columns\n",
    "        data = data.drop(columns=['attack', 'malicious', 'attack_number'], errors='ignore')\n",
    "        # Normalize Data\n",
    "        data_norm = scale_df(data, features)\n",
    "\n",
    "        # Parse and sort data\n",
    "        data_norm['_time'] = pd.to_datetime(data_norm['_time'])  \n",
    "        data_norm.sort_values(by=['imeisv', '_time'], inplace=True)\n",
    "\n",
    "        # Create Sequences\n",
    "        all_sequences, all_labels = [], []\n",
    "        target = 'binary_label'\n",
    "        for (imeisv, event), group in data_norm.groupby(['imeisv', 'event']):\n",
    "            if len(group) > ws:\n",
    "                sequences, labels = create_sequences_for_group(group, features, target, ws)\n",
    "                all_sequences.extend(sequences)\n",
    "                all_labels.extend(labels)\n",
    "\n",
    "        # Store the computed sequences\n",
    "        precomputed_sequences[attack] = (np.array(all_sequences), np.array(all_labels))\n",
    "\n",
    "        print(f\"✅ Completed {attack}: {len(all_sequences)} sequences stored.\")\n",
    "\n",
    "    return precomputed_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1044be7d-71bb-4a22-91b2-27cf50a9b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(sequences, features, ws, previous_data_ratio, csv_path):\n",
    "    attacks = ['SYN', 'ICMP', 'UDP', 'DNS', 'GTPU'] # Order of attacks: SYN - ICMP - UDP - DNS - GTPU \n",
    "    models = [] # store models for each day\n",
    "    results = [] # store results of cumulative evaluations (up to day x)\n",
    "    per_day_results = []  # Store per-day evaluations\n",
    "    future_days_evaluation = {}  # Store future days' evaluations\n",
    "    past_evaluation_results = {}  # Store evaluations on previous days' test sets\n",
    "    cumulative_X_test, cumulative_y_test = np.array([]), np.array([]) # Initialize cumulative test sets\n",
    "    test_sets = {} # Initialize a dictionary to store test sets for future and past evaluations\n",
    "    previous_normal_data, previous_attack_data = [], [] # Initialize buffers for sampled data \n",
    "    \n",
    "    # Training and fine-tuning loop\n",
    "    for i, attack in enumerate(attacks):\n",
    "        \n",
    "        all_sequences, all_labels = sequences[attack] \n",
    "        X = np.array(all_sequences)\n",
    "        y = np.array(all_labels)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "        \n",
    "        test_sets[i] = (X_test, y_test) # Save current test set for evaluations\n",
    "        # Concatenate cumulative test sets for evaluation\n",
    "        cumulative_X_test = np.concatenate([cumulative_X_test, X_test]) if cumulative_X_test.size else X_test\n",
    "        cumulative_y_test = np.concatenate([cumulative_y_test, y_test]) if cumulative_y_test.size else y_test\n",
    "    \n",
    "        # Stratified mixing of previous data\n",
    "        if i > 0 and (previous_normal_data or previous_attack_data):\n",
    "            print(f\"Mixing {previous_data_ratio * 100:.0f}% of previous days' data with current day's data\")\n",
    "\n",
    "            # Use only the last stored array instead of concatenating all\n",
    "            sampled_X_normal = previous_normal_data[-1] \n",
    "            sampled_X_attack = previous_attack_data[-1] \n",
    "    \n",
    "            # Combine normal and attack samples\n",
    "            sampled_previous_X = np.concatenate((sampled_X_normal, sampled_X_attack), axis=0)\n",
    "            sampled_previous_y = np.concatenate((np.zeros(len(sampled_X_normal)), np.ones(len(sampled_X_attack))), axis=0)\n",
    "    \n",
    "            # Combine sampled previous data with current day's training data\n",
    "            mixed_X_train = np.concatenate((X_train, sampled_previous_X), axis=0)\n",
    "            mixed_y_train = np.concatenate((y_train, sampled_previous_y), axis=0)\n",
    "            mixed_X_train, mixed_y_train = shuffle(mixed_X_train, mixed_y_train, random_state=42) # Shuffle the combined data\n",
    "        else:\n",
    "            mixed_X_train = X_train\n",
    "            mixed_y_train = y_train\n",
    "    \n",
    "        # Train or fine-tune the model\n",
    "        # early stopping\n",
    "        early_stopping = EarlyStopping( monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "        if i == 0: # Initial training\n",
    "            model = lstm_model(input_shape=X_train.shape[1:])\n",
    "            print(model.summary())\n",
    "            model.fit(mixed_X_train, mixed_y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "        else:  # Fine-tune\n",
    "            model.fit(mixed_X_train, mixed_y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "        models.append(model) # Save the model\n",
    "    \n",
    "        # Sampling data from the current day's training set for future use\n",
    "        print(f\"Sampling data from current training set for future use...\")    \n",
    "        shuffled_normal_X = shuffle(mixed_X_train[mixed_y_train == 0], random_state=42) # Shuffle and sample normal data\n",
    "        num_normal_samples = int(previous_data_ratio * len(shuffled_normal_X)) # get ratio of normal data\n",
    "        previous_normal_data.append(shuffled_normal_X[:num_normal_samples])\n",
    "\n",
    "        shuffled_attack_X = shuffle(mixed_X_train[mixed_y_train == 1], random_state=42) # Shuffle and sample attack data\n",
    "        num_attack_samples = int(previous_data_ratio * len(shuffled_attack_X)) # get ratio of attack data\n",
    "        previous_attack_data.append(shuffled_attack_X[:num_attack_samples])\n",
    "\n",
    "        results_list = []\n",
    "        # Per day evaluation\n",
    "        print(f\"Evaluating Model of Day {i + 1} on Day {i + 1} Test Set...\")\n",
    "        per_day_loss, per_day_accuracy, per_day_precision, per_day_recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "        predictions = model.predict(X_test)\n",
    "        predicted_labels = (predictions >= 0.5).astype(int).flatten()\n",
    "        class_report = classification_report(y_test, predicted_labels, target_names=[\"Normal\", \"Attack\"], output_dict=True)\n",
    "        conf_matrix = confusion_matrix(y_test, predicted_labels)\n",
    "        results_list.append([i + 1, \"Per-Day\", ws, per_day_loss, per_day_accuracy, per_day_precision, per_day_recall, class_report, conf_matrix.tolist()])\n",
    "        \n",
    "        # Evaluate cumulative test set\n",
    "        cumulative_loss, cumulative_accuracy, cumulative_precision, cumulative_recall = model.evaluate(cumulative_X_test, cumulative_y_test, verbose=0)\n",
    "        predictions = model.predict(cumulative_X_test)\n",
    "        predicted_labels = (predictions >= 0.5).astype(int).flatten()\n",
    "        class_report = classification_report(cumulative_y_test, predicted_labels, target_names=[\"Normal\", \"Attack\"], output_dict=True)\n",
    "        conf_matrix = confusion_matrix(cumulative_y_test, predicted_labels)\n",
    "        results_list.append([i + 1, \"Cumulative\", ws, cumulative_loss, cumulative_accuracy, cumulative_precision, cumulative_recall, class_report, conf_matrix.tolist()])\n",
    "        \n",
    "        # Evaluate on previous days' test sets\n",
    "        if i > 0:\n",
    "            for prev_day in range(i):\n",
    "                prev_X_test, prev_y_test = test_sets[prev_day]\n",
    "                prev_loss, prev_accuracy, prev_precision, prev_recall = model.evaluate(prev_X_test, prev_y_test, verbose=0)\n",
    "                predictions = model.predict(prev_X_test)\n",
    "                predicted_labels = (predictions >= 0.5).astype(int).flatten()\n",
    "                class_report = classification_report(prev_y_test, predicted_labels, target_names=[\"Normal\", \"Attack\"], output_dict=True)\n",
    "                conf_matrix = confusion_matrix(prev_y_test, predicted_labels)\n",
    "                results_list.append([i + 1, f\"Previous Day {prev_day + 1}\", ws, prev_loss, prev_accuracy, prev_precision, prev_recall, class_report, conf_matrix.tolist()])\n",
    "        \n",
    "        # Append results to CSV file\n",
    "        df_results = pd.DataFrame(results_list, columns=[\"Day\", \"Evaluation Type\", \"Window Size\", \"Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"Classification Report\", \"Confusion Matrix\"])\n",
    "        df_results.to_csv(csv_path, mode='a', header=not pd.io.common.file_exists(csv_path), index=False)\n",
    "        \n",
    "    print(\"\\nPerforming Future Test Set Evaluations:\")\n",
    "    for i, model in enumerate(models):\n",
    "        for j in range(i + 1, len(attacks)):\n",
    "            future_X_test, future_y_test = test_sets[j]\n",
    "            future_loss, future_accuracy, future_precision, future_recall = model.evaluate(future_X_test, future_y_test, verbose=0)\n",
    "            predictions = model.predict(future_X_test)\n",
    "            predicted_labels = (predictions >= 0.5).astype(int).flatten()\n",
    "            class_report = classification_report(future_y_test, predicted_labels, target_names=[\"Normal\", \"Attack\"], output_dict=True)\n",
    "            conf_matrix = confusion_matrix(future_y_test, predicted_labels)\n",
    "            df_results = pd.DataFrame([[i + 1, f\"Future Day {j + 1}\", ws, future_loss, future_accuracy, future_precision, future_recall, class_report, conf_matrix.tolist()]],\n",
    "                                      columns=[\"Day\", \"Evaluation Type\", \"Window Size\", \"Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"Classification Report\", \"Confusion Matrix\"])\n",
    "            df_results.to_csv(csv_path, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be6bee8-092e-49d4-93db-49f349cd65d5",
   "metadata": {},
   "source": [
    "#### Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1ad0b7-404c-4fd4-914b-1cf6fd5aa0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../Datasets/Per_Attack_Datasets'\n",
    "dataframes = read_data(folder_path)\n",
    "\n",
    "features = ['epre','pusch_snr','p_ue','ul_mcs','cqi','ul_bitrate',\n",
    "            'dl_mcs','dl_retx','ul_tx','dl_tx','ul_retx','dl_bitrate','dl_err','ul_err'] # features in the dataset\n",
    "num_features = 14 # number of features \n",
    "previous_data_ratio = 0.3  # Ratio of previous training data to be used\n",
    "ws = 5  # Window size\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists before calling training\n",
    "output_dir = \"Experiments_11_03_25\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Creates the directory if it doesn't exist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c26b430-b999-428b-9db0-de3a062b9474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Precomputing sequences for DNS\n",
      "✅ Completed DNS: 162599 sequences stored.\n",
      "🔄 Precomputing sequences for GTPU\n",
      "✅ Completed GTPU: 107063 sequences stored.\n",
      "🔄 Precomputing sequences for ICMP\n",
      "✅ Completed ICMP: 169966 sequences stored.\n",
      "🔄 Precomputing sequences for SYN\n",
      "✅ Completed SYN: 132194 sequences stored.\n",
      "🔄 Precomputing sequences for UDP\n",
      "✅ Completed UDP: 113607 sequences stored.\n",
      "Window size 10\n",
      "Ratio 0.5\n",
      "Iteration 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,016</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m14\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_layer (\u001b[38;5;33mLSTM\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m6,016\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,049</span> (23.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,049\u001b[0m (23.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,049</span> (23.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,049\u001b[0m (23.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/100\n",
      "\u001b[1m1322/1322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0497 - precision: 0.5834 - recall: 0.1970 - val_accuracy: 0.9998 - val_loss: 0.0022 - val_precision: 1.0000 - val_recall: 0.9804\n",
      "Epoch 2/100\n",
      "\u001b[1m1322/1322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0068 - precision: 0.9794 - recall: 0.8970 - val_accuracy: 0.9998 - val_loss: 0.0020 - val_precision: 1.0000 - val_recall: 0.9804\n",
      "Epoch 3/100\n",
      "\u001b[1m1322/1322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0070 - precision: 0.9689 - recall: 0.9102 - val_accuracy: 0.9999 - val_loss: 7.4159e-04 - val_precision: 1.0000 - val_recall: 0.9902\n",
      "Epoch 4/100\n",
      "\u001b[1m1322/1322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0015 - precision: 0.9727 - recall: 0.9776 - val_accuracy: 0.9999 - val_loss: 6.5123e-04 - val_precision: 1.0000 - val_recall: 0.9902\n",
      "Epoch 5/100\n",
      "\u001b[1m1322/1322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0015 - precision: 0.9889 - recall: 0.9822 - val_accuracy: 0.9999 - val_loss: 8.0193e-04 - val_precision: 1.0000 - val_recall: 0.9902\n",
      "Epoch 6/100\n",
      "\u001b[1m1322/1322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 5.3666e-04 - precision: 0.9904 - recall: 0.9986 - val_accuracy: 1.0000 - val_loss: 5.5096e-04 - val_precision: 1.0000 - val_recall: 0.9951\n",
      "Epoch 7/100\n",
      "\u001b[1m1322/1322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 7.2458e-04 - precision: 0.9844 - recall: 0.9927 - val_accuracy: 0.9999 - val_loss: 0.0014 - val_precision: 1.0000 - val_recall: 0.9902\n",
      "Epoch 8/100\n",
      "\u001b[1m1322/1322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0010 - precision: 0.9934 - recall: 0.9847 - val_accuracy: 0.9999 - val_loss: 6.7911e-04 - val_precision: 1.0000 - val_recall: 0.9902\n",
      "Epoch 9/100\n",
      "\u001b[1m1322/1322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 4.9343e-04 - precision: 0.9926 - recall: 0.9990 - val_accuracy: 1.0000 - val_loss: 5.5643e-04 - val_precision: 1.0000 - val_recall: 0.9951\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Sampling data from current training set for future use...\n",
      "Evaluating Model of Day 1 on Day 1 Test Set...\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step\n",
      "Mixing 50% of previous days' data with current day's data\n",
      "Epoch 1/100\n",
      "\u001b[1m2361/2361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0062 - precision: 0.9404 - recall: 0.9818 - val_accuracy: 0.9988 - val_loss: 0.0048 - val_precision: 0.9442 - val_recall: 1.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m2361/2361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0046 - precision: 0.9462 - recall: 0.9972 - val_accuracy: 0.9988 - val_loss: 0.0045 - val_precision: 0.9441 - val_recall: 0.9987\n",
      "Epoch 3/100\n",
      "\u001b[1m2361/2361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0041 - precision: 0.9508 - recall: 0.9973 - val_accuracy: 0.9989 - val_loss: 0.0046 - val_precision: 0.9454 - val_recall: 1.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m2361/2361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0038 - precision: 0.9557 - recall: 0.9976 - val_accuracy: 0.9988 - val_loss: 0.0051 - val_precision: 0.9451 - val_recall: 0.9946\n",
      "Epoch 5/100\n",
      "\u001b[1m2361/2361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0047 - precision: 0.9495 - recall: 0.9930 - val_accuracy: 0.9988 - val_loss: 0.0046 - val_precision: 0.9430 - val_recall: 1.0000\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Sampling data from current training set for future use...\n",
      "Evaluating Model of Day 2 on Day 2 Test Set...\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step\n",
      "\u001b[1m1889/1889\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 930us/step\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "Mixing 50% of previous days' data with current day's data\n",
      "Epoch 1/100\n",
      "\u001b[1m2317/2317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0049 - precision: 0.9424 - recall: 0.9699 - val_accuracy: 0.9996 - val_loss: 0.0020 - val_precision: 0.9784 - val_recall: 0.9983\n",
      "Epoch 2/100\n",
      "\u001b[1m2317/2317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0027 - precision: 0.9643 - recall: 0.9970 - val_accuracy: 0.9996 - val_loss: 0.0024 - val_precision: 0.9767 - val_recall: 0.9983\n",
      "Epoch 3/100\n",
      "\u001b[1m2317/2317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0031 - precision: 0.9617 - recall: 0.9983 - val_accuracy: 0.9996 - val_loss: 0.0021 - val_precision: 0.9784 - val_recall: 0.9983\n",
      "Epoch 4/100\n",
      "\u001b[1m2317/2317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0032 - precision: 0.9567 - recall: 0.9974 - val_accuracy: 0.9996 - val_loss: 0.0019 - val_precision: 0.9767 - val_recall: 0.9983\n",
      "Epoch 5/100\n",
      "\u001b[1m2317/2317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0029 - precision: 0.9613 - recall: 0.9971 - val_accuracy: 0.9996 - val_loss: 0.0021 - val_precision: 0.9767 - val_recall: 0.9983\n",
      "Epoch 6/100\n",
      "\u001b[1m2317/2317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0029 - precision: 0.9579 - recall: 0.9982 - val_accuracy: 0.9996 - val_loss: 0.0021 - val_precision: 0.9767 - val_recall: 0.9966\n",
      "Epoch 7/100\n",
      "\u001b[1m2317/2317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0025 - precision: 0.9648 - recall: 0.9961 - val_accuracy: 0.9996 - val_loss: 0.0019 - val_precision: 0.9784 - val_recall: 0.9983\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Sampling data from current training set for future use...\n",
      "Evaluating Model of Day 3 on Day 3 Test Set...\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step\n",
      "\u001b[1m2599/2599\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 928us/step\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step\n",
      "Mixing 50% of previous days' data with current day's data\n",
      "Epoch 1/100\n",
      "\u001b[1m2785/2785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0075 - precision: 0.9694 - recall: 0.9398 - val_accuracy: 0.9997 - val_loss: 0.0013 - val_precision: 0.9778 - val_recall: 0.9981\n",
      "Epoch 2/100\n",
      "\u001b[1m2785/2785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0016 - precision: 0.9728 - recall: 0.9932 - val_accuracy: 0.9997 - val_loss: 0.0011 - val_precision: 0.9742 - val_recall: 1.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m2785/2785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0015 - precision: 0.9729 - recall: 0.9966 - val_accuracy: 0.9997 - val_loss: 0.0013 - val_precision: 0.9796 - val_recall: 0.9981\n",
      "Epoch 4/100\n",
      "\u001b[1m2785/2785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 9.6447e-04 - precision: 0.9840 - recall: 0.9970 - val_accuracy: 0.9997 - val_loss: 0.0011 - val_precision: 0.9760 - val_recall: 1.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m2785/2785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9788 - recall: 0.9989 - val_accuracy: 0.9997 - val_loss: 0.0011 - val_precision: 0.9742 - val_recall: 1.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m2785/2785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0010 - precision: 0.9814 - recall: 0.9982 - val_accuracy: 0.9997 - val_loss: 9.7660e-04 - val_precision: 0.9778 - val_recall: 1.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m2785/2785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9765 - recall: 0.9967 - val_accuracy: 0.9997 - val_loss: 0.0011 - val_precision: 0.9760 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m2785/2785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0014 - precision: 0.9735 - recall: 0.9964 - val_accuracy: 0.9997 - val_loss: 0.0012 - val_precision: 0.9760 - val_recall: 1.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m2785/2785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9760 - recall: 0.9960 - val_accuracy: 0.9997 - val_loss: 0.0012 - val_precision: 0.9760 - val_recall: 1.0000\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Sampling data from current training set for future use...\n",
      "Evaluating Model of Day 4 on Day 4 Test Set...\n",
      "\u001b[1m1017/1017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step\n",
      "\u001b[1m3615/3615\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 956us/step\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step\n",
      "Mixing 50% of previous days' data with current day's data\n",
      "Epoch 1/100\n",
      "\u001b[1m2463/2463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0269 - precision: 0.9240 - recall: 0.6912 - val_accuracy: 0.9948 - val_loss: 0.0190 - val_precision: 0.9181 - val_recall: 0.8366\n",
      "Epoch 2/100\n",
      "\u001b[1m2463/2463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0174 - precision: 0.9257 - recall: 0.8133 - val_accuracy: 0.9946 - val_loss: 0.0173 - val_precision: 0.9821 - val_recall: 0.7678\n",
      "Epoch 3/100\n",
      "\u001b[1m2463/2463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0155 - precision: 0.9517 - recall: 0.8253 - val_accuracy: 0.9955 - val_loss: 0.0144 - val_precision: 0.9450 - val_recall: 0.8425\n",
      "Epoch 4/100\n",
      "\u001b[1m2463/2463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0141 - precision: 0.9570 - recall: 0.8443 - val_accuracy: 0.9961 - val_loss: 0.0136 - val_precision: 0.9809 - val_recall: 0.8390\n",
      "Epoch 5/100\n",
      "\u001b[1m2463/2463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0121 - precision: 0.9706 - recall: 0.8652 - val_accuracy: 0.9962 - val_loss: 0.0135 - val_precision: 0.9796 - val_recall: 0.8425\n",
      "Epoch 6/100\n",
      "\u001b[1m2463/2463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0133 - precision: 0.9654 - recall: 0.8568 - val_accuracy: 0.9953 - val_loss: 0.0157 - val_precision: 0.9855 - val_recall: 0.7958\n",
      "Epoch 7/100\n",
      "\u001b[1m2463/2463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0126 - precision: 0.9780 - recall: 0.8531 - val_accuracy: 0.9956 - val_loss: 0.0180 - val_precision: 0.9900 - val_recall: 0.8063\n",
      "Epoch 8/100\n",
      "\u001b[1m2463/2463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0121 - precision: 0.9784 - recall: 0.8622 - val_accuracy: 0.9962 - val_loss: 0.0135 - val_precision: 0.9876 - val_recall: 0.8355\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Sampling data from current training set for future use...\n",
      "Evaluating Model of Day 5 on Day 5 Test Set...\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step\n",
      "\u001b[1m4284/4284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 952us/step\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step\n",
      "\u001b[1m1017/1017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step\n",
      "\n",
      "Performing Future Test Set Evaluations:\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m1017/1017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step\n",
      "\u001b[1m1017/1017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m1017/1017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "ws = [10]\n",
    "ratio = [0.5] \n",
    "for ws_i in ws:\n",
    "    sequences = precompute_sequences(dataframes, features, ws_i)\n",
    "    print(f\"Window size {ws_i}\")\n",
    "    for r in ratio: \n",
    "        print(f\"Ratio {r}\")\n",
    "        for i in range(9,10):\n",
    "            print(f\"Iteration {i}\")\n",
    "            training(sequences, features, ws_i, r,f\"{output_dir}/experiments_{ws_i}_{r}_iter_{i}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3aee6-a4a6-4a83-b830-2d03c2e39d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
